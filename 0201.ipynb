{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, random\n",
    "\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input, TimeDistributed, GRU, SimpleRNN, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Bidirectional, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('./0130/')\n",
    "for file in files:\n",
    "    pd.read_csv('./0130/'+file, compression='gzip').to_csv('./0216/'+file[:-5], index=False, header=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bd sn ht mt lt oh ch cr ri\n",
    "checking_arr = [\n",
    "    # [0, 0, 0, 0, 0, 0, 0, 0, 0], # 0 null\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0], # 1  B\n",
    "    [1, 0, 0, 0, 0, 0, 0, 1, 0], # 2  B+C\n",
    "    [1, 0, 0, 0, 0, 0, 1, 0, 0], # 3  B+CH\n",
    "    [1, 0, 0, 0, 1, 0, 0, 0, 0], # 5  B+FT\n",
    "    [1, 0, 1, 0, 0, 0, 0, 0, 0], # 4  B+HT\n",
    "    [1, 0, 0, 1, 0, 0, 0, 0, 0], # 6  B+MT\n",
    "    [1, 0, 0, 0, 0, 1, 0, 0, 0], # 7  B+OH\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 1], # 8  B+R\n",
    "    [0, 0, 0, 0, 0, 0, 1, 0, 0], # 9  CH\n",
    "    [0, 0, 0, 0, 1, 0, 1, 0, 0], # 11 CH+FT\n",
    "    [0, 0, 1, 0, 0, 0, 1, 0, 0], # 10 CH+HT\n",
    "    [0, 0, 0, 0, 0, 0, 1, 0, 1], # 12 CH+R\n",
    "    [0, 0, 0, 0, 1, 0, 0, 0, 0], # 15 FT\n",
    "    [0, 0, 1, 0, 0, 0, 0, 0, 0], # 13 HT\n",
    "    [0, 0, 1, 0, 1, 0, 0, 0, 0], # 14 HT+FT\n",
    "    [0, 0, 0, 1, 0, 0, 0, 0, 0], # 16 MT\n",
    "    [0, 0, 0, 0, 0, 1, 0, 0, 0], # 17 OH\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 1], # 18 R\n",
    "    [0, 1, 0, 0, 0, 0, 0, 0, 0], # 19 S\n",
    "    [1, 1, 0, 0, 0, 0, 0, 0, 0], # 20 S+B\n",
    "    [1, 1, 0, 0, 0, 0, 1, 0, 0], # 21 S+B+CH\n",
    "    [1, 1, 0, 0, 1, 0, 0, 0, 0], # 22 S+B+FT\n",
    "    [1, 1, 0, 0, 0, 1, 0, 0, 0], # 23 S+B+OH\n",
    "    [1, 1, 0, 0, 0, 0, 0, 0, 1], # 24 S+B+R\n",
    "    [0, 1, 0, 0, 0, 0, 0, 1, 0], # 25 S+C\n",
    "    [0, 1, 0, 0, 0, 0, 1, 0, 0], # 26 S+CH\n",
    "    [0, 1, 0, 0, 1, 0, 0, 0, 0], # 27 S+FT\n",
    "    [0, 1, 0, 0, 0, 1, 0, 0, 0], # 28 S+OH\n",
    "    [0, 1, 0, 0, 0, 0, 0, 0, 1], # 29 S+R\n",
    "    # [0, 0, 0, 0, 0, 0, 0, 1, 0], # 30 C\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "barss = os.listdir('./bar2singlelabel_0213/')\n",
    "random.shuffle(barss)\n",
    "for i in barss:\n",
    "    tmp = pd.read_csv('./bar2singlelabel_0213/' + i, compression='gzip').to_numpy()\n",
    "    #### if tmp[-1][0] != 1:\n",
    "    # tmp = []\n",
    "    # for j in tmpp:\n",
    "    #     if 1 in j:\n",
    "    #         tmp.append(checking_arr[list(j).index(1)+1])\n",
    "    #     else:\n",
    "    #         tmp.append(checking_arr[0])\n",
    "    tmpp = np.zeros((32,30))\n",
    "    for j in range(32):\n",
    "        if np.where(tmp[j]==1)[0].size > 0:\n",
    "            tmpp[j][np.where(tmp[j] == 1)] = 1\n",
    "        else:\n",
    "            tmpp[j][29] = 1\n",
    "    train_x.append(tmpp[:-1])\n",
    "    # # tmppp = np.zeros((3,32))\n",
    "    # tmppp = np.zeros((34,32))\n",
    "    # tmppp[0][30] = 1\n",
    "    # # tmppp[1][np.where(tmpp[-1] == 1)] = 1\n",
    "    # for j in range(32):\n",
    "    #     tmppp[-j-2][np.where(tmpp[j] == 1)] = 1\n",
    "    # tmppp[-1][31] = 1\n",
    "    # train_y.append(tmppp)\n",
    "    train_y.append(np.expand_dims(tmp[-1],axis=0))\n",
    "\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n",
      "asdf\n"
     ]
    }
   ],
   "source": [
    "for y in train_y:\n",
    "    # print(y[0])\n",
    "    if (y[0] == [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1]).all():\n",
    "        print('asdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(None,30))\n",
    "encoder_lstm = Bidirectional(LSTM(units=64, return_state=True, dropout=0.2, recurrent_dropout=0.2))\n",
    "# bid1 = LSTM(units=128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)\n",
    "# bid2 = LSTM(units=128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, go_backwards=True)\n",
    "# b = Bidirectional(bid1, backward_layer=bid2, input_shape=(32,29))\n",
    "\n",
    "encoder_outputs, f_state_h, f_state_c, b_state_h, b_state_c = encoder_lstm(encoder_inputs)\n",
    "\n",
    "state_h = Concatenate()([f_state_h, b_state_h])\n",
    "state_c = Concatenate()([f_state_c, b_state_c])\n",
    "\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None, 30))\n",
    "encoder_lstm = LSTM(units=128, return_state=True)\n",
    "\n",
    "# encoder_outputs은 여기서는 불필요\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "\n",
    "# LSTM은 바닐라 RNN과는 달리 상태가 두 개. 은닉 상태와 셀 상태.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None, 32))\n",
    "decoder_lstm = LSTM(units=128, return_sequences=True, return_state=True)\n",
    "\n",
    "# 디코더에게 인코더의 은닉 상태, 셀 상태를 전달.\n",
    "decoder_outputs, _, _= decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "\n",
    "decoder_softmax_layer = Dense(32, activation='softmax')\n",
    "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "decoder_inputs = Input(shape=(None,32))\n",
    "decoder_lstm = LSTM(units=128,return_sequences=True, return_state=True, dropout=0.2, recurrent_dropout=0.2)\n",
    "\n",
    "# dbid1 = LSTM(units=128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)\n",
    "# dbid2 = LSTM(units=128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, go_backwards=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state = encoder_states)\n",
    "\n",
    "decoder_dense = Dense(32, activation='softmax')\n",
    "\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "\n",
    "# # define inference encoder\n",
    "# encoder_model = Model(encoder_inputs, encoder_states)\n",
    "# # define inference decoder\n",
    "# decoder_state_input_h = Input(shape=(64*2,))\n",
    "# decoder_state_input_c = Input(shape=(64*2,))\n",
    "# decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "# decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "# decoder_states = [state_h, state_c]\n",
    "# decoder_outputs = decoder_dense(decoder_outputs)\n",
    "# decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./chkpnt/0210/seq2seq_single/cp-0025.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpnt_pth = './chkpnt/0214/single/cp-{epoch:04d}.ckpt'\n",
    "chkpnt_dir = os.path.dirname(chkpnt_pth)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=chkpnt_pth, save_weights_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = tf.keras.losses.CategoricalCrossentropy(), optimizer='rmsprop', metrics=['accuracy'])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n",
      "266/266 [==============================] - 145s 533ms/step - loss: 1.4136 - accuracy: 0.6148 - val_loss: 0.3605 - val_accuracy: 0.9594\n",
      "\n",
      "Epoch 00001: saving model to ./chkpnt/0214/single\\cp-0001.ckpt\n",
      "Epoch 2/4000\n",
      "266/266 [==============================] - 140s 526ms/step - loss: 0.2692 - accuracy: 0.9430 - val_loss: 0.0381 - val_accuracy: 0.9950\n",
      "\n",
      "Epoch 00002: saving model to ./chkpnt/0214/single\\cp-0002.ckpt\n",
      "Epoch 3/4000\n",
      "266/266 [==============================] - 142s 535ms/step - loss: 0.0830 - accuracy: 0.9863 - val_loss: 0.0085 - val_accuracy: 0.9989\n",
      "\n",
      "Epoch 00003: saving model to ./chkpnt/0214/single\\cp-0003.ckpt\n",
      "Epoch 4/4000\n",
      "113/266 [===========>..................] - ETA: 1:20 - loss: 0.0386 - accuracy: 0.9943"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\KIST\\Documents\\GitHub\\LSTM_Drummer\\0201.ipynb 셀 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/KIST/Documents/GitHub/LSTM_Drummer/0201.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39m/gpu:0\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/KIST/Documents/GitHub/LSTM_Drummer/0201.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     model\u001b[39m.\u001b[39;49mfit([train_x,train_y],train_y, epochs\u001b[39m=\u001b[39;49m\u001b[39m4000\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[callback, cp_callback],validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\KIST\\.conda\\envs\\spleeter\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1183\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1176\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1177\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1178\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1179\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1180\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1181\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1182\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1183\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1184\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1185\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\KIST\\.conda\\envs\\spleeter\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:889\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    886\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    888\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 889\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    891\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    892\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\KIST\\.conda\\envs\\spleeter\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    914\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    915\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 917\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    920\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    921\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\KIST\\.conda\\envs\\spleeter\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3023\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3020\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   3021\u001b[0m   (graph_function,\n\u001b[0;32m   3022\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   3024\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\KIST\\.conda\\envs\\spleeter\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1960\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1956\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1957\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1958\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1959\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1960\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1961\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1962\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1963\u001b[0m     args,\n\u001b[0;32m   1964\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1965\u001b[0m     executing_eagerly)\n\u001b[0;32m   1966\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\KIST\\.conda\\envs\\spleeter\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    592\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    593\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    594\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    595\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    596\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    597\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\KIST\\.conda\\envs\\spleeter\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     60\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    model.fit([train_x,train_y],train_y, epochs=4000, callbacks=[callback, cp_callback],validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Epoch 1/4000\n",
      "266/266 [==============================] - 145s 532ms/step - loss: 1.5490 - accuracy: 0.2937 - val_loss: 1.4040 - val_accuracy: 0.3560\n",
      "\n",
      "Epoch 00001: saving model to ./chkpnt/0213/single_not_reversed\\cp-0001.ckpt\n",
      "Epoch 2/4000\n",
      "266/266 [==============================] - 141s 530ms/step - loss: 1.2746 - accuracy: 0.4293 - val_loss: 1.1140 - val_accuracy: 0.5105\n",
      "\n",
      "Epoch 00002: saving model to ./chkpnt/0213/single_not_reversed\\cp-0002.ckpt\n",
      "Epoch 3/4000\n",
      "266/266 [==============================] - 141s 531ms/step - loss: 1.0415 - accuracy: 0.5333 - val_loss: 1.1489 - val_accuracy: 0.5490\n",
      "\n",
      "Epoch 00003: saving model to ./chkpnt/0213/single_not_reversed\\cp-0003.ckpt\n",
      "Epoch 4/4000\n",
      "266/266 [==============================] - 141s 529ms/step - loss: 0.9127 - accuracy: 0.5618 - val_loss: 0.6649 - val_accuracy: 0.6473\n",
      "\n",
      "Epoch 00004: saving model to ./chkpnt/0213/single_not_reversed\\cp-0004.ckpt\n",
      "Epoch 5/4000\n",
      "266/266 [==============================] - 140s 526ms/step - loss: 0.8394 - accuracy: 0.5743 - val_loss: 0.6901 - val_accuracy: 0.6422\n",
      "\n",
      "Epoch 00005: saving model to ./chkpnt/0213/single_not_reversed\\cp-0005.ckpt\n",
      "Epoch 6/4000\n",
      "266/266 [==============================] - 138s 521ms/step - loss: 0.8029 - accuracy: 0.5780 - val_loss: 0.6578 - val_accuracy: 0.6410\n",
      "\n",
      "Epoch 00006: saving model to ./chkpnt/0213/single_not_reversed\\cp-0006.ckpt\n",
      "Epoch 7/4000\n",
      "266/266 [==============================] - 142s 533ms/step - loss: 0.7753 - accuracy: 0.5819 - val_loss: 0.6552 - val_accuracy: 0.6451\n",
      "\n",
      "Epoch 00007: saving model to ./chkpnt/0213/single_not_reversed\\cp-0007.ckpt\n",
      "Epoch 8/4000\n",
      "266/266 [==============================] - 140s 527ms/step - loss: 0.7544 - accuracy: 0.5843 - val_loss: 0.7326 - val_accuracy: 0.6329\n",
      "\n",
      "Epoch 00008: saving model to ./chkpnt/0213/single_not_reversed\\cp-0008.ckpt\n",
      "Epoch 9/4000\n",
      "266/266 [==============================] - 141s 529ms/step - loss: 0.7419 - accuracy: 0.5857 - val_loss: 0.8202 - val_accuracy: 0.6258\n",
      "\n",
      "Epoch 00009: saving model to ./chkpnt/0213/single_not_reversed\\cp-0009.ckpt\n",
      "Epoch 10/4000\n",
      "266/266 [==============================] - 139s 524ms/step - loss: 0.7351 - accuracy: 0.5867 - val_loss: 0.6488 - val_accuracy: 0.6445\n",
      "\n",
      "Epoch 00010: saving model to ./chkpnt/0213/single_not_reversed\\cp-0010.ckpt\n",
      "Epoch 11/4000\n",
      "266/266 [==============================] - 140s 525ms/step - loss: 0.7266 - accuracy: 0.5883 - val_loss: 0.5468 - val_accuracy: 0.6500\n",
      "\n",
      "Epoch 00011: saving model to ./chkpnt/0213/single_not_reversed\\cp-0011.ckpt\n",
      "Epoch 12/4000\n",
      "266/266 [==============================] - 139s 522ms/step - loss: 0.7221 - accuracy: 0.5867 - val_loss: 0.6253 - val_accuracy: 0.6521\n",
      "\n",
      "Epoch 00012: saving model to ./chkpnt/0213/single_not_reversed\\cp-0012.ckpt\n",
      "Epoch 13/4000\n",
      "266/266 [==============================] - 140s 527ms/step - loss: 0.7188 - accuracy: 0.5863 - val_loss: 0.7661 - val_accuracy: 0.6238\n",
      "\n",
      "Epoch 00013: saving model to ./chkpnt/0213/single_not_reversed\\cp-0013.ckpt\n",
      "Epoch 14/4000\n",
      "266/266 [==============================] - 139s 522ms/step - loss: 0.7173 - accuracy: 0.5856 - val_loss: 0.5753 - val_accuracy: 0.6569\n",
      "\n",
      "Epoch 00014: saving model to ./chkpnt/0213/single_not_reversed\\cp-0014.ckpt\n",
      "Epoch 15/4000\n",
      "266/266 [==============================] - 141s 529ms/step - loss: 0.7157 - accuracy: 0.5852 - val_loss: 0.5594 - val_accuracy: 0.6529\n",
      "\n",
      "Epoch 00015: saving model to ./chkpnt/0213/single_not_reversed\\cp-0015.ckpt\n",
      "Epoch 16/4000\n",
      "266/266 [==============================] - 140s 528ms/step - loss: 0.7117 - accuracy: 0.5845 - val_loss: 0.6011 - val_accuracy: 0.6571\n",
      "\n",
      "Epoch 00016: saving model to ./chkpnt/0213/single_not_reversed\\cp-0016.ckpt\n",
      "Epoch 17/4000\n",
      "266/266 [==============================] - 140s 526ms/step - loss: 0.7085 - accuracy: 0.5856 - val_loss: 0.5422 - val_accuracy: 0.6527\n",
      "\n",
      "Epoch 00017: saving model to ./chkpnt/0213/single_not_reversed\\cp-0017.ckpt\n",
      "Epoch 18/4000\n",
      "266/266 [==============================] - 140s 525ms/step - loss: 0.7066 - accuracy: 0.5846 - val_loss: 0.5165 - val_accuracy: 0.6556\n",
      "\n",
      "Epoch 00018: saving model to ./chkpnt/0213/single_not_reversed\\cp-0018.ckpt\n",
      "Epoch 19/4000\n",
      "266/266 [==============================] - 140s 528ms/step - loss: 0.7032 - accuracy: 0.5876 - val_loss: 0.4750 - val_accuracy: 0.6618\n",
      "\n",
      "Epoch 00019: saving model to ./chkpnt/0213/single_not_reversed\\cp-0019.ckpt\n",
      "Epoch 20/4000\n",
      "266/266 [==============================] - 139s 522ms/step - loss: 0.7038 - accuracy: 0.5877 - val_loss: 0.4827 - val_accuracy: 0.6558\n",
      "\n",
      "Epoch 00020: saving model to ./chkpnt/0213/single_not_reversed\\cp-0020.ckpt\n",
      "Epoch 21/4000\n",
      "266/266 [==============================] - 140s 526ms/step - loss: 0.7033 - accuracy: 0.5895 - val_loss: 0.4940 - val_accuracy: 0.6569\n",
      "\n",
      "Epoch 00021: saving model to ./chkpnt/0213/single_not_reversed\\cp-0021.ckpt\n",
      "Epoch 22/4000\n",
      "266/266 [==============================] - 140s 527ms/step - loss: 0.7035 - accuracy: 0.5882 - val_loss: 0.4604 - val_accuracy: 0.6562\n",
      "\n",
      "Epoch 00022: saving model to ./chkpnt/0213/single_not_reversed\\cp-0022.ckpt\n",
      "Epoch 23/4000\n",
      "266/266 [==============================] - 140s 527ms/step - loss: 0.6994 - accuracy: 0.5897 - val_loss: 0.5227 - val_accuracy: 0.6457\n",
      "\n",
      "Epoch 00023: saving model to ./chkpnt/0213/single_not_reversed\\cp-0023.ckpt\n",
      "Epoch 24/4000\n",
      "266/266 [==============================] - 140s 527ms/step - loss: 0.6950 - accuracy: 0.5909 - val_loss: 0.4918 - val_accuracy: 0.6479\n",
      "\n",
      "Epoch 00024: saving model to ./chkpnt/0213/single_not_reversed\\cp-0024.ckpt\n",
      "Epoch 25/4000\n",
      "266/266 [==============================] - 140s 528ms/step - loss: 0.6942 - accuracy: 0.5903 - val_loss: 0.4907 - val_accuracy: 0.6524\n",
      "\n",
      "Epoch 00025: saving model to ./chkpnt/0213/single_not_reversed\\cp-0025.ckpt\n",
      "Epoch 26/4000\n",
      "266/266 [==============================] - 141s 530ms/step - loss: 0.6881 - accuracy: 0.5914 - val_loss: 0.4855 - val_accuracy: 0.6482\n",
      "\n",
      "Epoch 00026: saving model to ./chkpnt/0213/single_not_reversed\\cp-0026.ckpt\n",
      "Epoch 27/4000\n",
      "266/266 [==============================] - 141s 532ms/step - loss: 0.6823 - accuracy: 0.5923 - val_loss: 0.4564 - val_accuracy: 0.6605\n",
      "\n",
      "Epoch 00027: saving model to ./chkpnt/0213/single_not_reversed\\cp-0027.ckpt\n",
      "Epoch 28/4000\n",
      "266/266 [==============================] - 141s 529ms/step - loss: 0.6801 - accuracy: 0.5935 - val_loss: 0.5418 - val_accuracy: 0.6391\n",
      "\n",
      "Epoch 00028: saving model to ./chkpnt/0213/single_not_reversed\\cp-0028.ckpt\n",
      "Epoch 29/4000\n",
      "266/266 [==============================] - 139s 523ms/step - loss: 0.6776 - accuracy: 0.5938 - val_loss: 0.5069 - val_accuracy: 0.6463\n",
      "\n",
      "Epoch 00029: saving model to ./chkpnt/0213/single_not_reversed\\cp-0029.ckpt\n",
      "Epoch 30/4000\n",
      "266/266 [==============================] - 140s 527ms/step - loss: 0.6997 - accuracy: 0.5908 - val_loss: 0.6598 - val_accuracy: 0.5729\n",
      "\n",
      "Epoch 00030: saving model to ./chkpnt/0213/single_not_reversed\\cp-0030.ckpt\n",
      "Epoch 31/4000\n",
      "266/266 [==============================] - 140s 527ms/step - loss: 0.7191 - accuracy: 0.5897 - val_loss: 0.6102 - val_accuracy: 0.5860\n",
      "\n",
      "Epoch 00031: saving model to ./chkpnt/0213/single_not_reversed\\cp-0031.ckpt\n",
      "Epoch 32/4000\n",
      "266/266 [==============================] - 142s 533ms/step - loss: 0.7153 - accuracy: 0.5908 - val_loss: 0.7019 - val_accuracy: 0.5866\n",
      "\n",
      "Epoch 00032: saving model to ./chkpnt/0213/single_not_reversed\\cp-0032.ckpt\n",
      "Epoch 33/4000\n",
      "266/266 [==============================] - 139s 524ms/step - loss: 0.7116 - accuracy: 0.5921 - val_loss: 0.6334 - val_accuracy: 0.5963\n",
      "\n",
      "Epoch 00033: saving model to ./chkpnt/0213/single_not_reversed\\cp-0033.ckpt\n",
      "Epoch 34/4000\n",
      "266/266 [==============================] - 140s 527ms/step - loss: 0.7173 - accuracy: 0.5920 - val_loss: 0.7106 - val_accuracy: 0.6038\n",
      "\n",
      "Epoch 00034: saving model to ./chkpnt/0213/single_not_reversed\\cp-0034.ckpt\n"
     ]
    }
   ],
   "source": [
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "barss = os.listdir('./bar2singlelabel_0213/')\n",
    "random.shuffle(barss)\n",
    "for i in barss:\n",
    "    tmp = pd.read_csv('./bar2singlelabel_0213/' + i, compression='gzip').to_numpy()\n",
    "    train_x.append(tmp[:-1])\n",
    "    tmpp = np.zeros((34,31))\n",
    "    tmpp[0][29] = 1\n",
    "    for j in range(32):\n",
    "        tmpp[j+1][np.where(tmp[j] == 1)] = 1\n",
    "    tmpp[-1][30] = 1\n",
    "    train_y.append(tmpp)\n",
    "\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "\n",
    "encoder_inputs = Input(shape=(None,29))\n",
    "encoder_lstm = Bidirectional(LSTM(units=64, return_state=True, dropout=0.2, recurrent_dropout=0.2))\n",
    "encoder_outputs, f_state_h, f_state_c, b_state_h, b_state_c = encoder_lstm(encoder_inputs)\n",
    "state_h = Concatenate()([f_state_h, b_state_h])\n",
    "state_c = Concatenate()([f_state_c, b_state_c])\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(None,31))\n",
    "decoder_lstm = LSTM(units=128,return_sequences=True, return_state=True, dropout=0.2, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state = encoder_states)\n",
    "decoder_dense = Dense(31, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "chkpnt_pth = './chkpnt/0213/single_not_reversed/cp-{epoch:04d}.ckpt'\n",
    "chkpnt_dir = os.path.dirname(chkpnt_pth)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=chkpnt_pth, save_weights_only=True, verbose=1)\n",
    "\n",
    "model.compile(loss = tf.keras.losses.CategoricalCrossentropy(), optimizer='rmsprop', metrics=['accuracy'])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=7)\n",
    "\n",
    "with tf.device(\"/gpu:0\"):\n",
    "    model.fit([train_x,train_y],train_y, epochs=4000, callbacks=[callback, cp_callback],validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "01 : 25Epoch\n",
    "02 : 61Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(128,))\n",
    "decoder_state_input_c = Input(shape=(128,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용.\n",
    "# 뒤의 함수 decode_sequence()에 동작을 구현 예정\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태를 버리지 않음.\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "      # 입력으로부터 인코더의 상태를 얻음\n",
    "  states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "  # <SOS>에 해당하는 원-핫 벡터 생성\n",
    "  target_seq = np.zeros((1, 1, 32))\n",
    "  target_seq[0, 0, 30] = 1.\n",
    "  # target_seq = input_seq[0]\n",
    "\n",
    "  stop_condition = False\n",
    "  decoded_sentence = []\n",
    "\n",
    "  # stop_condition이 True가 될 때까지 루프 반복\n",
    "  while not stop_condition:\n",
    "  # while _ in range(32):\n",
    "    # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "    # 예측 결과를 문자로 변환\n",
    "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "    sampled_char = str(sampled_token_index)\n",
    "\n",
    "    # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "    decoded_sentence.append(sampled_char)\n",
    "    # decoded_sentence += '_'\n",
    "    \n",
    "    # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "    if (sampled_char == '31' or\n",
    "      len(decoded_sentence) > 34):\n",
    "      stop_condition = True\n",
    "    \n",
    "    # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "    target_seq = np.zeros((1, 1, 32))\n",
    "    target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "    # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "    states_value = [h, c]\n",
    "\n",
    "  return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['30',\n",
       " '27',\n",
       " '27',\n",
       " '27',\n",
       " '27',\n",
       " '27',\n",
       " '27',\n",
       " '27',\n",
       " '27',\n",
       " '27',\n",
       " '27',\n",
       " '27',\n",
       " '27',\n",
       " '27',\n",
       " '27',\n",
       " '27',\n",
       " '27',\n",
       " '27',\n",
       " '27',\n",
       " '27',\n",
       " '27',\n",
       " '27',\n",
       " '27',\n",
       " '27',\n",
       " '27',\n",
       " '27',\n",
       " '27',\n",
       " '27',\n",
       " '27',\n",
       " '27',\n",
       " '27',\n",
       " '27',\n",
       " '27',\n",
       " '27',\n",
       " '27']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_sequence(np.expand_dims(train_x[15], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size=0.2, random_state=1)\n",
    "x_valid_, x_test_, y_valid_, y_test_ = train_test_split(X_test, y_test, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1, 128), dtype=tf.float32, name=None), name='repeat_vector/Tile:0', description=\"created by layer 'repeat_vector'\")\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1, 128), dtype=tf.float32, name=None), name='lstm_1/transpose_1:0', description=\"created by layer 'lstm_1'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1, 31), dtype=tf.float32, name=None), name='activation/Softmax:0', description=\"created by layer 'activation'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1, 128), dtype=tf.float32, name=None), name='batch_normalization_2/batchnorm/add_1:0', description=\"created by layer 'batch_normalization_2'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1, 256), dtype=tf.float32, name=None), name='concatenate/concat:0', description=\"created by layer 'concatenate'\")\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1, 29), dtype=tf.float32, name=None), name='time_distributed/Reshape_1:0', description=\"created by layer 'time_distributed'\")\n"
     ]
    }
   ],
   "source": [
    "n_hidden=128\n",
    "input_train=tf.keras.Input(shape=(X_train.shape[1],X_train.shape[2]))\n",
    "output_train=tf.keras.Input(shape=(y_train.shape[1],y_train.shape[2]))\n",
    "\n",
    "encoder_stack_h, encoder_last_h, encoder_last_c = tf.keras.layers.LSTM(\n",
    "    n_hidden, activation='relu', \n",
    "    dropout=0.5, recurrent_dropout = 0.5,\n",
    "    return_state = True, return_sequences=True)(input_train)\n",
    "\n",
    "encoder_last_h = tf.keras.layers.BatchNormalization(momentum=0.6)(encoder_last_h)\n",
    "encoder_last_c = tf.keras.layers.BatchNormalization(momentum=0.6)(encoder_last_c)\n",
    "\n",
    "decoder_input = tf.keras.layers.RepeatVector(output_train.shape[1])(encoder_last_h)\n",
    "print(decoder_input)\n",
    "decoder_stack_h = tf.keras.layers.LSTM(n_hidden, \n",
    "               activation = 'relu',\n",
    "               dropout=0.5, \n",
    "               recurrent_dropout=0.5,\n",
    "               return_sequences = True,\n",
    "               return_state =False)(decoder_input, initial_state=[encoder_last_h, encoder_last_c])\n",
    "print(decoder_stack_h)\n",
    "\n",
    "attention = tf.keras.layers.dot([decoder_stack_h, encoder_stack_h], axes = [2,2])\n",
    "attention = tf.keras.layers.Activation('softmax')(attention)\n",
    "print(attention)\n",
    "context = tf.keras.layers.dot([attention, encoder_stack_h], axes = [2,1])\n",
    "context = tf.keras.layers.BatchNormalization(momentum = 0.6)(context)\n",
    "print(context)\n",
    "decoder_combined_context = tf.keras.layers.concatenate([context, decoder_stack_h])\n",
    "print(decoder_combined_context)\n",
    "out = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(output_train.shape[2], activation='softmax'))(decoder_combined_context)\n",
    "print(out)\n",
    "\n",
    "model = tf.keras.Model(inputs = input_train, outputs = out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = tf.keras.losses.CategoricalCrossentropy(), optimizer='rmsprop', metrics=['accuracy'])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4)\n",
    "\n",
    "chkpnt_pth = './chkpnt/0216/single/cp-{epoch:04d}.ckpt'\n",
    "chkpnt_dir = os.path.dirname(chkpnt_pth)\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=chkpnt_pth, save_weights_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n",
      "295/295 [==============================] - 67s 210ms/step - loss: 2.0778 - accuracy: 0.3420 - val_loss: 1.7550 - val_accuracy: 0.4093\n",
      "\n",
      "Epoch 00001: saving model to ./chkpnt/0216/single\\cp-0001.ckpt\n",
      "Epoch 2/4000\n",
      "295/295 [==============================] - 60s 204ms/step - loss: 1.8871 - accuracy: 0.3684 - val_loss: 1.7965 - val_accuracy: 0.3902\n",
      "\n",
      "Epoch 00002: saving model to ./chkpnt/0216/single\\cp-0002.ckpt\n",
      "Epoch 3/4000\n",
      "295/295 [==============================] - 60s 203ms/step - loss: 1.8457 - accuracy: 0.3802 - val_loss: 1.6467 - val_accuracy: 0.4231\n",
      "\n",
      "Epoch 00003: saving model to ./chkpnt/0216/single\\cp-0003.ckpt\n",
      "Epoch 4/4000\n",
      "295/295 [==============================] - 61s 208ms/step - loss: 1.8123 - accuracy: 0.3890 - val_loss: 1.6192 - val_accuracy: 0.4517\n",
      "\n",
      "Epoch 00004: saving model to ./chkpnt/0216/single\\cp-0004.ckpt\n",
      "Epoch 5/4000\n",
      "295/295 [==============================] - 63s 214ms/step - loss: 1.7824 - accuracy: 0.3983 - val_loss: 1.5983 - val_accuracy: 0.4443\n",
      "\n",
      "Epoch 00005: saving model to ./chkpnt/0216/single\\cp-0005.ckpt\n",
      "Epoch 6/4000\n",
      "295/295 [==============================] - 59s 201ms/step - loss: 1.7656 - accuracy: 0.4061 - val_loss: 1.6061 - val_accuracy: 0.4274\n",
      "\n",
      "Epoch 00006: saving model to ./chkpnt/0216/single\\cp-0006.ckpt\n",
      "Epoch 7/4000\n",
      "295/295 [==============================] - 59s 199ms/step - loss: 1.7557 - accuracy: 0.4106 - val_loss: 1.5595 - val_accuracy: 0.4592\n",
      "\n",
      "Epoch 00007: saving model to ./chkpnt/0216/single\\cp-0007.ckpt\n",
      "Epoch 8/4000\n",
      "295/295 [==============================] - 60s 203ms/step - loss: 1.7338 - accuracy: 0.4145 - val_loss: 1.5705 - val_accuracy: 0.4528\n",
      "\n",
      "Epoch 00008: saving model to ./chkpnt/0216/single\\cp-0008.ckpt\n",
      "Epoch 9/4000\n",
      "295/295 [==============================] - 60s 204ms/step - loss: 1.7202 - accuracy: 0.4230 - val_loss: 1.5472 - val_accuracy: 0.4677\n",
      "\n",
      "Epoch 00009: saving model to ./chkpnt/0216/single\\cp-0009.ckpt\n",
      "Epoch 10/4000\n",
      "295/295 [==============================] - 59s 200ms/step - loss: 1.7041 - accuracy: 0.4304 - val_loss: 1.5572 - val_accuracy: 0.4666\n",
      "\n",
      "Epoch 00010: saving model to ./chkpnt/0216/single\\cp-0010.ckpt\n",
      "Epoch 11/4000\n",
      "295/295 [==============================] - 60s 202ms/step - loss: 1.6961 - accuracy: 0.4347 - val_loss: 1.5274 - val_accuracy: 0.4666\n",
      "\n",
      "Epoch 00011: saving model to ./chkpnt/0216/single\\cp-0011.ckpt\n",
      "Epoch 12/4000\n",
      "295/295 [==============================] - 59s 200ms/step - loss: 1.6738 - accuracy: 0.4420 - val_loss: 1.5032 - val_accuracy: 0.4889\n",
      "\n",
      "Epoch 00012: saving model to ./chkpnt/0216/single\\cp-0012.ckpt\n",
      "Epoch 13/4000\n",
      "295/295 [==============================] - 60s 202ms/step - loss: 1.6618 - accuracy: 0.4423 - val_loss: 1.4930 - val_accuracy: 0.4889\n",
      "\n",
      "Epoch 00013: saving model to ./chkpnt/0216/single\\cp-0013.ckpt\n",
      "Epoch 14/4000\n",
      "295/295 [==============================] - 58s 198ms/step - loss: 1.6493 - accuracy: 0.4507 - val_loss: 1.4673 - val_accuracy: 0.5027\n",
      "\n",
      "Epoch 00014: saving model to ./chkpnt/0216/single\\cp-0014.ckpt\n",
      "Epoch 15/4000\n",
      "295/295 [==============================] - 56s 190ms/step - loss: 1.6494 - accuracy: 0.4546 - val_loss: 1.4398 - val_accuracy: 0.5069\n",
      "\n",
      "Epoch 00015: saving model to ./chkpnt/0216/single\\cp-0015.ckpt\n",
      "Epoch 16/4000\n",
      "295/295 [==============================] - 59s 199ms/step - loss: 1.6372 - accuracy: 0.4622 - val_loss: 1.4468 - val_accuracy: 0.5122\n",
      "\n",
      "Epoch 00016: saving model to ./chkpnt/0216/single\\cp-0016.ckpt\n",
      "Epoch 17/4000\n",
      "295/295 [==============================] - 57s 194ms/step - loss: 1.6099 - accuracy: 0.4615 - val_loss: 1.4112 - val_accuracy: 0.5196\n",
      "\n",
      "Epoch 00017: saving model to ./chkpnt/0216/single\\cp-0017.ckpt\n",
      "Epoch 18/4000\n",
      "295/295 [==============================] - 58s 196ms/step - loss: 1.6159 - accuracy: 0.4736 - val_loss: 1.4235 - val_accuracy: 0.5143\n",
      "\n",
      "Epoch 00018: saving model to ./chkpnt/0216/single\\cp-0018.ckpt\n",
      "Epoch 19/4000\n",
      "295/295 [==============================] - 59s 199ms/step - loss: 1.6048 - accuracy: 0.4684 - val_loss: 1.3666 - val_accuracy: 0.5525\n",
      "\n",
      "Epoch 00019: saving model to ./chkpnt/0216/single\\cp-0019.ckpt\n",
      "Epoch 20/4000\n",
      "295/295 [==============================] - 57s 194ms/step - loss: 1.5945 - accuracy: 0.4753 - val_loss: 1.3828 - val_accuracy: 0.5514\n",
      "\n",
      "Epoch 00020: saving model to ./chkpnt/0216/single\\cp-0020.ckpt\n",
      "Epoch 21/4000\n",
      "295/295 [==============================] - 59s 201ms/step - loss: 1.5886 - accuracy: 0.4800 - val_loss: 1.4004 - val_accuracy: 0.5154\n",
      "\n",
      "Epoch 00021: saving model to ./chkpnt/0216/single\\cp-0021.ckpt\n",
      "Epoch 22/4000\n",
      "295/295 [==============================] - 60s 204ms/step - loss: 1.5813 - accuracy: 0.4883 - val_loss: 1.3761 - val_accuracy: 0.5366\n",
      "\n",
      "Epoch 00022: saving model to ./chkpnt/0216/single\\cp-0022.ckpt\n",
      "Epoch 23/4000\n",
      "295/295 [==============================] - 61s 205ms/step - loss: 1.5714 - accuracy: 0.4840 - val_loss: 1.3548 - val_accuracy: 0.5483\n",
      "\n",
      "Epoch 00023: saving model to ./chkpnt/0216/single\\cp-0023.ckpt\n",
      "Epoch 24/4000\n",
      "295/295 [==============================] - 57s 194ms/step - loss: 1.5674 - accuracy: 0.4900 - val_loss: 1.3613 - val_accuracy: 0.5716\n",
      "\n",
      "Epoch 00024: saving model to ./chkpnt/0216/single\\cp-0024.ckpt\n",
      "Epoch 25/4000\n",
      "295/295 [==============================] - 54s 184ms/step - loss: 1.5476 - accuracy: 0.4981 - val_loss: 1.3452 - val_accuracy: 0.5419\n",
      "\n",
      "Epoch 00025: saving model to ./chkpnt/0216/single\\cp-0025.ckpt\n",
      "Epoch 26/4000\n",
      "295/295 [==============================] - 55s 188ms/step - loss: 1.5477 - accuracy: 0.4910 - val_loss: 1.3123 - val_accuracy: 0.5737\n",
      "\n",
      "Epoch 00026: saving model to ./chkpnt/0216/single\\cp-0026.ckpt\n",
      "Epoch 27/4000\n",
      "295/295 [==============================] - 60s 204ms/step - loss: 1.5557 - accuracy: 0.4929 - val_loss: 1.3319 - val_accuracy: 0.5673\n",
      "\n",
      "Epoch 00027: saving model to ./chkpnt/0216/single\\cp-0027.ckpt\n",
      "Epoch 28/4000\n",
      "295/295 [==============================] - 60s 204ms/step - loss: 1.5411 - accuracy: 0.5019 - val_loss: 1.2865 - val_accuracy: 0.5928\n",
      "\n",
      "Epoch 00028: saving model to ./chkpnt/0216/single\\cp-0028.ckpt\n",
      "Epoch 29/4000\n",
      "295/295 [==============================] - 59s 201ms/step - loss: 1.5262 - accuracy: 0.5049 - val_loss: 1.2613 - val_accuracy: 0.6129\n",
      "\n",
      "Epoch 00029: saving model to ./chkpnt/0216/single\\cp-0029.ckpt\n",
      "Epoch 30/4000\n",
      "295/295 [==============================] - 59s 201ms/step - loss: 1.5251 - accuracy: 0.5033 - val_loss: 1.2897 - val_accuracy: 0.5631\n",
      "\n",
      "Epoch 00030: saving model to ./chkpnt/0216/single\\cp-0030.ckpt\n",
      "Epoch 31/4000\n",
      "295/295 [==============================] - 60s 202ms/step - loss: 1.5276 - accuracy: 0.5050 - val_loss: 1.2665 - val_accuracy: 0.5970\n",
      "\n",
      "Epoch 00031: saving model to ./chkpnt/0216/single\\cp-0031.ckpt\n",
      "Epoch 32/4000\n",
      "295/295 [==============================] - 61s 206ms/step - loss: 1.5101 - accuracy: 0.5090 - val_loss: 1.2737 - val_accuracy: 0.5843\n",
      "\n",
      "Epoch 00032: saving model to ./chkpnt/0216/single\\cp-0032.ckpt\n",
      "Epoch 33/4000\n",
      "295/295 [==============================] - 60s 204ms/step - loss: 1.4997 - accuracy: 0.5139 - val_loss: 1.2419 - val_accuracy: 0.6119\n",
      "\n",
      "Epoch 00033: saving model to ./chkpnt/0216/single\\cp-0033.ckpt\n",
      "Epoch 34/4000\n",
      "295/295 [==============================] - 61s 206ms/step - loss: 1.5068 - accuracy: 0.5122 - val_loss: 1.2181 - val_accuracy: 0.5907\n",
      "\n",
      "Epoch 00034: saving model to ./chkpnt/0216/single\\cp-0034.ckpt\n",
      "Epoch 35/4000\n",
      "295/295 [==============================] - 61s 206ms/step - loss: 1.5052 - accuracy: 0.5152 - val_loss: 1.2076 - val_accuracy: 0.6182\n",
      "\n",
      "Epoch 00035: saving model to ./chkpnt/0216/single\\cp-0035.ckpt\n",
      "Epoch 36/4000\n",
      "295/295 [==============================] - 60s 204ms/step - loss: 1.5103 - accuracy: 0.5151 - val_loss: 1.2170 - val_accuracy: 0.6045\n",
      "\n",
      "Epoch 00036: saving model to ./chkpnt/0216/single\\cp-0036.ckpt\n",
      "Epoch 37/4000\n",
      "295/295 [==============================] - 59s 201ms/step - loss: 1.4866 - accuracy: 0.5243 - val_loss: 1.1909 - val_accuracy: 0.6214\n",
      "\n",
      "Epoch 00037: saving model to ./chkpnt/0216/single\\cp-0037.ckpt\n",
      "Epoch 38/4000\n",
      "295/295 [==============================] - 59s 201ms/step - loss: 1.4905 - accuracy: 0.5149 - val_loss: 1.2019 - val_accuracy: 0.6193\n",
      "\n",
      "Epoch 00038: saving model to ./chkpnt/0216/single\\cp-0038.ckpt\n",
      "Epoch 39/4000\n",
      "295/295 [==============================] - 60s 203ms/step - loss: 1.4744 - accuracy: 0.5292 - val_loss: 1.1758 - val_accuracy: 0.6140\n",
      "\n",
      "Epoch 00039: saving model to ./chkpnt/0216/single\\cp-0039.ckpt\n",
      "Epoch 40/4000\n",
      "295/295 [==============================] - 60s 203ms/step - loss: 1.4561 - accuracy: 0.5277 - val_loss: 1.1899 - val_accuracy: 0.6151\n",
      "\n",
      "Epoch 00040: saving model to ./chkpnt/0216/single\\cp-0040.ckpt\n",
      "Epoch 41/4000\n",
      "295/295 [==============================] - 60s 204ms/step - loss: 1.4796 - accuracy: 0.5248 - val_loss: 1.1587 - val_accuracy: 0.6172\n",
      "\n",
      "Epoch 00041: saving model to ./chkpnt/0216/single\\cp-0041.ckpt\n",
      "Epoch 42/4000\n",
      "295/295 [==============================] - 59s 202ms/step - loss: 1.4580 - accuracy: 0.5299 - val_loss: 1.1471 - val_accuracy: 0.6310\n",
      "\n",
      "Epoch 00042: saving model to ./chkpnt/0216/single\\cp-0042.ckpt\n",
      "Epoch 43/4000\n",
      "295/295 [==============================] - 57s 195ms/step - loss: 1.4616 - accuracy: 0.5352 - val_loss: 1.1636 - val_accuracy: 0.6087\n",
      "\n",
      "Epoch 00043: saving model to ./chkpnt/0216/single\\cp-0043.ckpt\n",
      "Epoch 44/4000\n",
      "295/295 [==============================] - 57s 193ms/step - loss: 1.4580 - accuracy: 0.5330 - val_loss: 1.1579 - val_accuracy: 0.6373\n",
      "\n",
      "Epoch 00044: saving model to ./chkpnt/0216/single\\cp-0044.ckpt\n",
      "Epoch 45/4000\n",
      "295/295 [==============================] - 60s 204ms/step - loss: 1.4560 - accuracy: 0.5287 - val_loss: 1.1296 - val_accuracy: 0.6288\n",
      "\n",
      "Epoch 00045: saving model to ./chkpnt/0216/single\\cp-0045.ckpt\n",
      "Epoch 46/4000\n",
      "295/295 [==============================] - 59s 201ms/step - loss: 1.4499 - accuracy: 0.5351 - val_loss: 1.1284 - val_accuracy: 0.6352\n",
      "\n",
      "Epoch 00046: saving model to ./chkpnt/0216/single\\cp-0046.ckpt\n",
      "Epoch 47/4000\n",
      "295/295 [==============================] - 60s 204ms/step - loss: 1.4506 - accuracy: 0.5388 - val_loss: 1.1389 - val_accuracy: 0.6299\n",
      "\n",
      "Epoch 00047: saving model to ./chkpnt/0216/single\\cp-0047.ckpt\n",
      "Epoch 48/4000\n",
      "295/295 [==============================] - 60s 202ms/step - loss: 1.4365 - accuracy: 0.5428 - val_loss: 1.1098 - val_accuracy: 0.6363\n",
      "\n",
      "Epoch 00048: saving model to ./chkpnt/0216/single\\cp-0048.ckpt\n",
      "Epoch 49/4000\n",
      "295/295 [==============================] - 61s 206ms/step - loss: 1.4303 - accuracy: 0.5420 - val_loss: 1.1440 - val_accuracy: 0.6129\n",
      "\n",
      "Epoch 00049: saving model to ./chkpnt/0216/single\\cp-0049.ckpt\n",
      "Epoch 50/4000\n",
      "295/295 [==============================] - 59s 201ms/step - loss: 1.4126 - accuracy: 0.5377 - val_loss: 1.1372 - val_accuracy: 0.6235\n",
      "\n",
      "Epoch 00050: saving model to ./chkpnt/0216/single\\cp-0050.ckpt\n",
      "Epoch 51/4000\n",
      "295/295 [==============================] - 60s 202ms/step - loss: 1.4094 - accuracy: 0.5469 - val_loss: 1.1176 - val_accuracy: 0.6416\n",
      "\n",
      "Epoch 00051: saving model to ./chkpnt/0216/single\\cp-0051.ckpt\n",
      "Epoch 52/4000\n",
      "295/295 [==============================] - 59s 200ms/step - loss: 1.4156 - accuracy: 0.5422 - val_loss: 1.0977 - val_accuracy: 0.6458\n",
      "\n",
      "Epoch 00052: saving model to ./chkpnt/0216/single\\cp-0052.ckpt\n",
      "Epoch 53/4000\n",
      "295/295 [==============================] - 57s 194ms/step - loss: 1.4125 - accuracy: 0.5383 - val_loss: 1.0887 - val_accuracy: 0.6363\n",
      "\n",
      "Epoch 00053: saving model to ./chkpnt/0216/single\\cp-0053.ckpt\n",
      "Epoch 54/4000\n",
      "295/295 [==============================] - 58s 198ms/step - loss: 1.4022 - accuracy: 0.5459 - val_loss: 1.0909 - val_accuracy: 0.6458\n",
      "\n",
      "Epoch 00054: saving model to ./chkpnt/0216/single\\cp-0054.ckpt\n",
      "Epoch 55/4000\n",
      "295/295 [==============================] - 59s 201ms/step - loss: 1.4183 - accuracy: 0.5437 - val_loss: 1.1074 - val_accuracy: 0.6278\n",
      "\n",
      "Epoch 00055: saving model to ./chkpnt/0216/single\\cp-0055.ckpt\n",
      "Epoch 56/4000\n",
      "295/295 [==============================] - 58s 197ms/step - loss: 1.3906 - accuracy: 0.5514 - val_loss: 1.0865 - val_accuracy: 0.6331\n",
      "\n",
      "Epoch 00056: saving model to ./chkpnt/0216/single\\cp-0056.ckpt\n",
      "Epoch 57/4000\n",
      "295/295 [==============================] - 58s 196ms/step - loss: 1.3926 - accuracy: 0.5444 - val_loss: 1.0958 - val_accuracy: 0.6182\n",
      "\n",
      "Epoch 00057: saving model to ./chkpnt/0216/single\\cp-0057.ckpt\n",
      "Epoch 58/4000\n",
      "295/295 [==============================] - 59s 199ms/step - loss: 1.4027 - accuracy: 0.5471 - val_loss: 1.1101 - val_accuracy: 0.6246\n",
      "\n",
      "Epoch 00058: saving model to ./chkpnt/0216/single\\cp-0058.ckpt\n",
      "Epoch 59/4000\n",
      "295/295 [==============================] - 59s 199ms/step - loss: 1.3681 - accuracy: 0.5583 - val_loss: 1.0759 - val_accuracy: 0.6469\n",
      "\n",
      "Epoch 00059: saving model to ./chkpnt/0216/single\\cp-0059.ckpt\n",
      "Epoch 60/4000\n",
      "295/295 [==============================] - 58s 197ms/step - loss: 1.3840 - accuracy: 0.5553 - val_loss: 1.0401 - val_accuracy: 0.6437\n",
      "\n",
      "Epoch 00060: saving model to ./chkpnt/0216/single\\cp-0060.ckpt\n",
      "Epoch 61/4000\n",
      "295/295 [==============================] - 57s 194ms/step - loss: 1.3767 - accuracy: 0.5516 - val_loss: 1.0482 - val_accuracy: 0.6617\n",
      "\n",
      "Epoch 00061: saving model to ./chkpnt/0216/single\\cp-0061.ckpt\n",
      "Epoch 62/4000\n",
      "295/295 [==============================] - 59s 199ms/step - loss: 1.3803 - accuracy: 0.5530 - val_loss: 1.0880 - val_accuracy: 0.6373\n",
      "\n",
      "Epoch 00062: saving model to ./chkpnt/0216/single\\cp-0062.ckpt\n",
      "Epoch 63/4000\n",
      "295/295 [==============================] - 58s 196ms/step - loss: 1.3812 - accuracy: 0.5573 - val_loss: 1.0679 - val_accuracy: 0.6341\n",
      "\n",
      "Epoch 00063: saving model to ./chkpnt/0216/single\\cp-0063.ckpt\n",
      "Epoch 64/4000\n",
      "295/295 [==============================] - 57s 193ms/step - loss: 1.3844 - accuracy: 0.5621 - val_loss: 1.0790 - val_accuracy: 0.6299\n",
      "\n",
      "Epoch 00064: saving model to ./chkpnt/0216/single\\cp-0064.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    model.fit(train_x,train_y, epochs=4000, callbacks=[callback, cp_callback],validation_data=(x_valid_, y_valid_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 1s 44ms/step - loss: 1.7833 - accuracy: 0.3835\n",
      "30/30 [==============================] - 1s 34ms/step - loss: 1.8117 - accuracy: 0.3771\n",
      "30/30 [==============================] - 1s 34ms/step - loss: 1.6546 - accuracy: 0.4142\n",
      "30/30 [==============================] - 1s 35ms/step - loss: 1.6214 - accuracy: 0.4407\n",
      "30/30 [==============================] - 1s 35ms/step - loss: 1.6019 - accuracy: 0.4544\n",
      "30/30 [==============================] - 1s 38ms/step - loss: 1.6113 - accuracy: 0.4301\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 1.5700 - accuracy: 0.4290\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 1.5657 - accuracy: 0.4470\n",
      "30/30 [==============================] - 1s 39ms/step - loss: 1.5407 - accuracy: 0.4587\n",
      "30/30 [==============================] - 1s 39ms/step - loss: 1.5353 - accuracy: 0.4746\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 1.5370 - accuracy: 0.4735\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 1.4918 - accuracy: 0.4968\n",
      "30/30 [==============================] - 1s 41ms/step - loss: 1.4849 - accuracy: 0.4926\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 1.4523 - accuracy: 0.5085\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 1.4273 - accuracy: 0.5117\n",
      "30/30 [==============================] - 1s 39ms/step - loss: 1.4644 - accuracy: 0.5095\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 1.4232 - accuracy: 0.5117\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 1.4403 - accuracy: 0.5127\n",
      "30/30 [==============================] - 1s 39ms/step - loss: 1.3967 - accuracy: 0.5318\n",
      "30/30 [==============================] - 1s 37ms/step - loss: 1.4057 - accuracy: 0.5424\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 1.3999 - accuracy: 0.5138\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 1.4075 - accuracy: 0.5222\n",
      "30/30 [==============================] - 1s 37ms/step - loss: 1.3790 - accuracy: 0.5371\n",
      "30/30 [==============================] - 1s 36ms/step - loss: 1.3653 - accuracy: 0.5498\n",
      "30/30 [==============================] - 1s 37ms/step - loss: 1.3478 - accuracy: 0.5371\n",
      "30/30 [==============================] - 1s 36ms/step - loss: 1.3456 - accuracy: 0.5445\n",
      "30/30 [==============================] - 1s 37ms/step - loss: 1.3419 - accuracy: 0.5424\n",
      "30/30 [==============================] - 1s 37ms/step - loss: 1.3129 - accuracy: 0.5625\n",
      "30/30 [==============================] - 1s 37ms/step - loss: 1.2939 - accuracy: 0.5752\n",
      "30/30 [==============================] - 1s 37ms/step - loss: 1.2920 - accuracy: 0.5614\n",
      "30/30 [==============================] - 1s 33ms/step - loss: 1.3030 - accuracy: 0.5763\n",
      "30/30 [==============================] - 1s 33ms/step - loss: 1.2861 - accuracy: 0.5742\n",
      "30/30 [==============================] - 1s 33ms/step - loss: 1.2895 - accuracy: 0.5805\n",
      "30/30 [==============================] - 1s 34ms/step - loss: 1.2708 - accuracy: 0.5689\n",
      "30/30 [==============================] - 1s 37ms/step - loss: 1.2496 - accuracy: 0.5879\n",
      "30/30 [==============================] - 1s 37ms/step - loss: 1.2475 - accuracy: 0.5847\n",
      "30/30 [==============================] - 1s 37ms/step - loss: 1.2253 - accuracy: 0.5953\n",
      "30/30 [==============================] - 1s 37ms/step - loss: 1.2567 - accuracy: 0.5847\n",
      "30/30 [==============================] - 1s 36ms/step - loss: 1.1953 - accuracy: 0.5996\n",
      "30/30 [==============================] - 1s 36ms/step - loss: 1.2282 - accuracy: 0.5932\n",
      "30/30 [==============================] - 1s 37ms/step - loss: 1.2010 - accuracy: 0.6017\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 1.2069 - accuracy: 0.6081\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 1.1915 - accuracy: 0.5985\n",
      "30/30 [==============================] - 1s 39ms/step - loss: 1.2081 - accuracy: 0.6218\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 1.1703 - accuracy: 0.6208\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 1.1500 - accuracy: 0.6155\n",
      "30/30 [==============================] - 1s 37ms/step - loss: 1.1464 - accuracy: 0.6303\n",
      "30/30 [==============================] - 1s 37ms/step - loss: 1.1546 - accuracy: 0.6250\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 1.1662 - accuracy: 0.6017\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 1.1415 - accuracy: 0.6197\n",
      "30/30 [==============================] - 1s 38ms/step - loss: 1.1532 - accuracy: 0.6218\n",
      "30/30 [==============================] - 1s 36ms/step - loss: 1.1015 - accuracy: 0.6398\n",
      "30/30 [==============================] - 1s 37ms/step - loss: 1.1109 - accuracy: 0.6314\n",
      "30/30 [==============================] - 1s 37ms/step - loss: 1.1121 - accuracy: 0.6335\n",
      "30/30 [==============================] - 1s 36ms/step - loss: 1.1200 - accuracy: 0.6314\n",
      "30/30 [==============================] - 1s 37ms/step - loss: 1.0842 - accuracy: 0.6409\n",
      "30/30 [==============================] - 1s 36ms/step - loss: 1.0940 - accuracy: 0.6282\n",
      "30/30 [==============================] - 1s 36ms/step - loss: 1.1138 - accuracy: 0.6208\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 1.1033 - accuracy: 0.6314\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 1.0607 - accuracy: 0.6271\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 1.0524 - accuracy: 0.6525\n",
      "30/30 [==============================] - 1s 40ms/step - loss: 1.0771 - accuracy: 0.6451\n",
      "30/30 [==============================] - 1s 39ms/step - loss: 1.0966 - accuracy: 0.6377\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,64):\n",
    "    model.load_weights('./chkpnt/0216/single/cp-'+str(i).zfill(4)+'.ckpt')\n",
    "    model.evaluate(x_test_, y_test_)\n",
    "    \n",
    "#EPOCH 61 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 30)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape[1],X_train.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spleeter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b3c401dacfab8a690b1a7de6c6a9edd3269fc10d243267328a900f27334b3a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
