{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, random\n",
    "\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input, TimeDistributed, GRU, SimpleRNN, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Bidirectional, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bd sn ht mt lt oh ch cr ri\n",
    "checking_arr = [\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 0], # 0 null\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 0], # 1  B\n",
    "    [1, 0, 0, 0, 0, 0, 0, 1, 0], # 2  B+C\n",
    "    [1, 0, 0, 0, 0, 0, 1, 0, 0], # 3  B+CH\n",
    "    [1, 0, 0, 0, 1, 0, 0, 0, 0], # 5  B+FT\n",
    "    [1, 0, 1, 0, 0, 0, 0, 0, 0], # 4  B+HT\n",
    "    [1, 0, 0, 1, 0, 0, 0, 0, 0], # 6  B+MT\n",
    "    [1, 0, 0, 0, 0, 1, 0, 0, 0], # 7  B+OH\n",
    "    [1, 0, 0, 0, 0, 0, 0, 0, 1], # 8  B+R\n",
    "    [0, 0, 0, 0, 0, 0, 1, 0, 0], # 9  CH\n",
    "    [0, 0, 0, 0, 1, 0, 1, 0, 0], # 11 CH+FT\n",
    "    [0, 0, 1, 0, 0, 0, 1, 0, 0], # 10 CH+HT\n",
    "    [0, 0, 0, 0, 0, 0, 1, 0, 1], # 12 CH+R\n",
    "    [0, 0, 0, 0, 1, 0, 0, 0, 0], # 15 FT\n",
    "    [0, 0, 1, 0, 0, 0, 0, 0, 0], # 13 HT\n",
    "    [0, 0, 1, 0, 1, 0, 0, 0, 0], # 14 HT+FT\n",
    "    [0, 0, 0, 1, 0, 0, 0, 0, 0], # 16 MT\n",
    "    [0, 0, 0, 0, 0, 1, 0, 0, 0], # 17 OH\n",
    "    [0, 0, 0, 0, 0, 0, 0, 0, 1], # 18 R\n",
    "    [0, 1, 0, 0, 0, 0, 0, 0, 0], # 19 S\n",
    "    [1, 1, 0, 0, 0, 0, 0, 0, 0], # 20 S+B\n",
    "    [1, 1, 0, 0, 0, 0, 1, 0, 0], # 21 S+B+CH\n",
    "    [1, 1, 0, 0, 1, 0, 0, 0, 0], # 22 S+B+FT\n",
    "    [1, 1, 0, 0, 0, 1, 0, 0, 0], # 23 S+B+OH\n",
    "    [1, 1, 0, 0, 0, 0, 0, 0, 1], # 24 S+B+R\n",
    "    [0, 1, 0, 0, 0, 0, 0, 1, 0], # 25 S+C\n",
    "    [0, 1, 0, 0, 0, 0, 1, 0, 0], # 26 S+CH\n",
    "    [0, 1, 0, 0, 1, 0, 0, 0, 0], # 27 S+FT\n",
    "    [0, 1, 0, 0, 0, 1, 0, 0, 0], # 28 S+OH\n",
    "    [0, 1, 0, 0, 0, 0, 0, 0, 1], # 29 S+R\n",
    "    # [0, 0, 0, 0, 0, 0, 0, 1, 0], # 30 C\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "barss = os.listdir('./bar2singlelabel_0111_/')\n",
    "random.shuffle(barss)\n",
    "for i in barss:\n",
    "    tmpp = pd.read_csv('./bar2singlelabel_0111_/' + i, compression='gzip').to_numpy()\n",
    "    #### if tmp[-1][0] != 1:\n",
    "    tmp = []\n",
    "    for j in tmpp:\n",
    "        if 1 in j:\n",
    "            tmp.append(checking_arr[list(j).index(1)+1])\n",
    "        else:\n",
    "            tmp.append(checking_arr[0])\n",
    "    train_x.append(tmp[:-1])\n",
    "    train_y.append(tmp)\n",
    "\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_40 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(None,29))\n",
    "encoder_lstm = Bidirectional(LSTM(units=64, return_state=True, dropout=0.2, recurrent_dropout=0.2))\n",
    "# bid1 = LSTM(units=128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)\n",
    "# bid2 = LSTM(units=128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, go_backwards=True)\n",
    "# b = Bidirectional(bid1, backward_layer=bid2, input_shape=(32,29))\n",
    "\n",
    "encoder_outputs, f_state_h, f_state_c, b_state_h, b_state_c = encoder_lstm(encoder_inputs)\n",
    "\n",
    "state_h = Concatenate()([f_state_h, b_state_h])\n",
    "state_c = Concatenate()([f_state_c, b_state_c])\n",
    "\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_41 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "decoder_inputs = Input(shape=(None,29))\n",
    "decoder_lstm = LSTM(units=128,return_sequences=True, return_state=True, dropout=0.2, recurrent_dropout=0.2)\n",
    "\n",
    "# dbid1 = LSTM(units=128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2)\n",
    "# dbid2 = LSTM(units=128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2, go_backwards=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state = encoder_states)\n",
    "\n",
    "decoder_dense = Dense(29, activation='sigmoid')\n",
    "\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "\n",
    "# # define inference encoder\n",
    "# encoder_model = Model(encoder_inputs, encoder_states)\n",
    "# # define inference decoder\n",
    "# decoder_state_input_h = Input(shape=(64*2,))\n",
    "# decoder_state_input_c = Input(shape=(64*2,))\n",
    "# decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "# decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "# decoder_states = [state_h, state_c]\n",
    "# decoder_outputs = decoder_dense(decoder_outputs)\n",
    "# decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2427f6d2f40>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('./chkpnt/0210/seq2seq_single/cp-0025.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "chkpnt_pth = './chkpnt/0210/seq2seq_multi/cp-{epoch:04d}.ckpt'\n",
    "chkpnt_dir = os.path.dirname(chkpnt_pth)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=chkpnt_pth, save_weights_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = tf.keras.losses.MSE, optimizer='adam', metrics=['accuracy'])\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4000\n",
      "275/275 [==============================] - 150s 534ms/step - loss: 0.0664 - accuracy: 0.4041 - val_loss: 0.0309 - val_accuracy: 0.5043\n",
      "\n",
      "Epoch 00001: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0001.ckpt\n",
      "Epoch 2/4000\n",
      "275/275 [==============================] - 142s 518ms/step - loss: 0.0218 - accuracy: 0.5616 - val_loss: 0.0083 - val_accuracy: 0.5676\n",
      "\n",
      "Epoch 00002: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0002.ckpt\n",
      "Epoch 3/4000\n",
      "275/275 [==============================] - 143s 521ms/step - loss: 0.0104 - accuracy: 0.5953 - val_loss: 0.0034 - val_accuracy: 0.5964\n",
      "\n",
      "Epoch 00003: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0003.ckpt\n",
      "Epoch 4/4000\n",
      "275/275 [==============================] - 142s 518ms/step - loss: 0.0064 - accuracy: 0.6080 - val_loss: 0.0021 - val_accuracy: 0.5951\n",
      "\n",
      "Epoch 00004: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0004.ckpt\n",
      "Epoch 5/4000\n",
      "275/275 [==============================] - 148s 539ms/step - loss: 0.0048 - accuracy: 0.6182 - val_loss: 0.0017 - val_accuracy: 0.5972\n",
      "\n",
      "Epoch 00005: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0005.ckpt\n",
      "Epoch 6/4000\n",
      "275/275 [==============================] - 149s 541ms/step - loss: 0.0037 - accuracy: 0.6254 - val_loss: 0.0013 - val_accuracy: 0.6257\n",
      "\n",
      "Epoch 00006: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0006.ckpt\n",
      "Epoch 7/4000\n",
      "275/275 [==============================] - 148s 539ms/step - loss: 0.0030 - accuracy: 0.6295 - val_loss: 8.9417e-04 - val_accuracy: 0.6416\n",
      "\n",
      "Epoch 00007: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0007.ckpt\n",
      "Epoch 8/4000\n",
      "275/275 [==============================] - 146s 530ms/step - loss: 0.0023 - accuracy: 0.6373 - val_loss: 4.6154e-04 - val_accuracy: 0.6734\n",
      "\n",
      "Epoch 00008: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0008.ckpt\n",
      "Epoch 9/4000\n",
      "275/275 [==============================] - 144s 524ms/step - loss: 0.0018 - accuracy: 0.6393 - val_loss: 2.9090e-04 - val_accuracy: 0.6593\n",
      "\n",
      "Epoch 00009: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0009.ckpt\n",
      "Epoch 10/4000\n",
      "275/275 [==============================] - 146s 529ms/step - loss: 0.0016 - accuracy: 0.6401 - val_loss: 2.9541e-04 - val_accuracy: 0.7025\n",
      "\n",
      "Epoch 00010: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0010.ckpt\n",
      "Epoch 11/4000\n",
      "275/275 [==============================] - 145s 527ms/step - loss: 0.0014 - accuracy: 0.6484 - val_loss: 2.4385e-04 - val_accuracy: 0.6640\n",
      "\n",
      "Epoch 00011: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0011.ckpt\n",
      "Epoch 12/4000\n",
      "275/275 [==============================] - 146s 530ms/step - loss: 0.0012 - accuracy: 0.6527 - val_loss: 2.2063e-04 - val_accuracy: 0.7099\n",
      "\n",
      "Epoch 00012: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0012.ckpt\n",
      "Epoch 13/4000\n",
      "275/275 [==============================] - 147s 536ms/step - loss: 0.0011 - accuracy: 0.6553 - val_loss: 1.8873e-04 - val_accuracy: 0.7336\n",
      "\n",
      "Epoch 00013: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0013.ckpt\n",
      "Epoch 14/4000\n",
      "275/275 [==============================] - 145s 526ms/step - loss: 0.0010 - accuracy: 0.6568 - val_loss: 1.8061e-04 - val_accuracy: 0.7327\n",
      "\n",
      "Epoch 00014: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0014.ckpt\n",
      "Epoch 15/4000\n",
      "275/275 [==============================] - 146s 530ms/step - loss: 9.0627e-04 - accuracy: 0.6649 - val_loss: 1.2001e-04 - val_accuracy: 0.7822\n",
      "\n",
      "Epoch 00015: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0015.ckpt\n",
      "Epoch 16/4000\n",
      "275/275 [==============================] - 145s 529ms/step - loss: 8.3005e-04 - accuracy: 0.6679 - val_loss: 1.0055e-04 - val_accuracy: 0.8158\n",
      "\n",
      "Epoch 00016: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0016.ckpt\n",
      "Epoch 17/4000\n",
      "275/275 [==============================] - 145s 528ms/step - loss: 7.7097e-04 - accuracy: 0.6687 - val_loss: 1.0864e-04 - val_accuracy: 0.7330\n",
      "\n",
      "Epoch 00017: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0017.ckpt\n",
      "Epoch 18/4000\n",
      "275/275 [==============================] - 146s 530ms/step - loss: 7.0222e-04 - accuracy: 0.6747 - val_loss: 8.2305e-05 - val_accuracy: 0.7572\n",
      "\n",
      "Epoch 00018: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0018.ckpt\n",
      "Epoch 19/4000\n",
      "275/275 [==============================] - 146s 532ms/step - loss: 6.6759e-04 - accuracy: 0.6710 - val_loss: 6.7175e-05 - val_accuracy: 0.7429\n",
      "\n",
      "Epoch 00019: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0019.ckpt\n",
      "Epoch 20/4000\n",
      "275/275 [==============================] - 144s 523ms/step - loss: 6.2308e-04 - accuracy: 0.6754 - val_loss: 6.8949e-05 - val_accuracy: 0.7615\n",
      "\n",
      "Epoch 00020: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0020.ckpt\n",
      "Epoch 21/4000\n",
      "275/275 [==============================] - 145s 526ms/step - loss: 5.6922e-04 - accuracy: 0.6766 - val_loss: 5.3170e-05 - val_accuracy: 0.7688\n",
      "\n",
      "Epoch 00021: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0021.ckpt\n",
      "Epoch 22/4000\n",
      "275/275 [==============================] - 145s 526ms/step - loss: 5.3033e-04 - accuracy: 0.6835 - val_loss: 7.3691e-05 - val_accuracy: 0.7486\n",
      "\n",
      "Epoch 00022: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0022.ckpt\n",
      "Epoch 23/4000\n",
      "275/275 [==============================] - 144s 523ms/step - loss: 4.8404e-04 - accuracy: 0.6805 - val_loss: 5.9801e-05 - val_accuracy: 0.8102\n",
      "\n",
      "Epoch 00023: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0023.ckpt\n",
      "Epoch 24/4000\n",
      "275/275 [==============================] - 145s 528ms/step - loss: 4.6151e-04 - accuracy: 0.6848 - val_loss: 3.5780e-05 - val_accuracy: 0.7734\n",
      "\n",
      "Epoch 00024: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0024.ckpt\n",
      "Epoch 25/4000\n",
      "275/275 [==============================] - 143s 522ms/step - loss: 4.3955e-04 - accuracy: 0.6762 - val_loss: 4.9943e-05 - val_accuracy: 0.7808\n",
      "\n",
      "Epoch 00025: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0025.ckpt\n",
      "Epoch 26/4000\n",
      "275/275 [==============================] - 146s 530ms/step - loss: 4.0861e-04 - accuracy: 0.6787 - val_loss: 3.6446e-05 - val_accuracy: 0.8772\n",
      "\n",
      "Epoch 00026: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0026.ckpt\n",
      "Epoch 27/4000\n",
      "275/275 [==============================] - 144s 523ms/step - loss: 4.0345e-04 - accuracy: 0.6797 - val_loss: 3.4128e-05 - val_accuracy: 0.7472\n",
      "\n",
      "Epoch 00027: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0027.ckpt\n",
      "Epoch 28/4000\n",
      "275/275 [==============================] - 147s 534ms/step - loss: 3.8686e-04 - accuracy: 0.6742 - val_loss: 2.7603e-05 - val_accuracy: 0.8136\n",
      "\n",
      "Epoch 00028: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0028.ckpt\n",
      "Epoch 29/4000\n",
      "275/275 [==============================] - 146s 532ms/step - loss: 3.4902e-04 - accuracy: 0.6777 - val_loss: 2.8318e-05 - val_accuracy: 0.7444\n",
      "\n",
      "Epoch 00029: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0029.ckpt\n",
      "Epoch 30/4000\n",
      "275/275 [==============================] - 145s 526ms/step - loss: 3.3022e-04 - accuracy: 0.6824 - val_loss: 1.8836e-05 - val_accuracy: 0.7962\n",
      "\n",
      "Epoch 00030: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0030.ckpt\n",
      "Epoch 31/4000\n",
      "275/275 [==============================] - 142s 518ms/step - loss: 3.2079e-04 - accuracy: 0.6851 - val_loss: 2.2154e-05 - val_accuracy: 0.7515\n",
      "\n",
      "Epoch 00031: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0031.ckpt\n",
      "Epoch 32/4000\n",
      "275/275 [==============================] - 143s 521ms/step - loss: 3.2610e-04 - accuracy: 0.6913 - val_loss: 2.5355e-05 - val_accuracy: 0.7813\n",
      "\n",
      "Epoch 00032: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0032.ckpt\n",
      "Epoch 33/4000\n",
      "275/275 [==============================] - 143s 519ms/step - loss: 3.0900e-04 - accuracy: 0.6928 - val_loss: 1.5534e-05 - val_accuracy: 0.7504\n",
      "\n",
      "Epoch 00033: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0033.ckpt\n",
      "Epoch 34/4000\n",
      "275/275 [==============================] - 143s 519ms/step - loss: 3.0587e-04 - accuracy: 0.6981 - val_loss: 1.5253e-05 - val_accuracy: 0.7456\n",
      "\n",
      "Epoch 00034: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0034.ckpt\n",
      "Epoch 35/4000\n",
      "275/275 [==============================] - 144s 522ms/step - loss: 2.8880e-04 - accuracy: 0.7053 - val_loss: 1.2031e-05 - val_accuracy: 0.7754\n",
      "\n",
      "Epoch 00035: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0035.ckpt\n",
      "Epoch 36/4000\n",
      "275/275 [==============================] - 143s 519ms/step - loss: 2.7265e-04 - accuracy: 0.7093 - val_loss: 9.9022e-06 - val_accuracy: 0.7495\n",
      "\n",
      "Epoch 00036: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0036.ckpt\n",
      "Epoch 37/4000\n",
      "275/275 [==============================] - 144s 523ms/step - loss: 2.6521e-04 - accuracy: 0.7126 - val_loss: 9.3840e-06 - val_accuracy: 0.7601\n",
      "\n",
      "Epoch 00037: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0037.ckpt\n",
      "Epoch 38/4000\n",
      "275/275 [==============================] - 144s 523ms/step - loss: 2.8200e-04 - accuracy: 0.7120 - val_loss: 9.1878e-06 - val_accuracy: 0.7518\n",
      "\n",
      "Epoch 00038: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0038.ckpt\n",
      "Epoch 39/4000\n",
      "275/275 [==============================] - 144s 525ms/step - loss: 2.6789e-04 - accuracy: 0.7130 - val_loss: 1.3072e-05 - val_accuracy: 0.7432\n",
      "\n",
      "Epoch 00039: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0039.ckpt\n",
      "Epoch 40/4000\n",
      "275/275 [==============================] - 143s 518ms/step - loss: 2.5156e-04 - accuracy: 0.7221 - val_loss: 9.8034e-06 - val_accuracy: 0.7661\n",
      "\n",
      "Epoch 00040: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0040.ckpt\n",
      "Epoch 41/4000\n",
      "275/275 [==============================] - 144s 523ms/step - loss: 2.5250e-04 - accuracy: 0.7187 - val_loss: 9.2208e-06 - val_accuracy: 0.7957\n",
      "\n",
      "Epoch 00041: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0041.ckpt\n",
      "Epoch 42/4000\n",
      "275/275 [==============================] - 142s 518ms/step - loss: 2.5312e-04 - accuracy: 0.7203 - val_loss: 7.8212e-06 - val_accuracy: 0.7687\n",
      "\n",
      "Epoch 00042: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0042.ckpt\n",
      "Epoch 43/4000\n",
      "275/275 [==============================] - 144s 524ms/step - loss: 2.4493e-04 - accuracy: 0.7260 - val_loss: 9.2697e-06 - val_accuracy: 0.7609\n",
      "\n",
      "Epoch 00043: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0043.ckpt\n",
      "Epoch 44/4000\n",
      "275/275 [==============================] - 143s 521ms/step - loss: 2.3647e-04 - accuracy: 0.7252 - val_loss: 8.2936e-06 - val_accuracy: 0.8406\n",
      "\n",
      "Epoch 00044: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0044.ckpt\n",
      "Epoch 45/4000\n",
      "275/275 [==============================] - 143s 521ms/step - loss: 2.4520e-04 - accuracy: 0.7242 - val_loss: 8.0958e-06 - val_accuracy: 0.7422\n",
      "\n",
      "Epoch 00045: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0045.ckpt\n",
      "Epoch 46/4000\n",
      "275/275 [==============================] - 145s 526ms/step - loss: 2.2760e-04 - accuracy: 0.7268 - val_loss: 4.9541e-06 - val_accuracy: 0.7452\n",
      "\n",
      "Epoch 00046: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0046.ckpt\n",
      "Epoch 47/4000\n",
      "275/275 [==============================] - 142s 515ms/step - loss: 2.2439e-04 - accuracy: 0.7258 - val_loss: 5.5286e-06 - val_accuracy: 0.7451\n",
      "\n",
      "Epoch 00047: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0047.ckpt\n",
      "Epoch 48/4000\n",
      "275/275 [==============================] - 143s 519ms/step - loss: 2.3123e-04 - accuracy: 0.7281 - val_loss: 7.6538e-06 - val_accuracy: 0.7748\n",
      "\n",
      "Epoch 00048: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0048.ckpt\n",
      "Epoch 49/4000\n",
      "275/275 [==============================] - 141s 514ms/step - loss: 2.4242e-04 - accuracy: 0.7198 - val_loss: 5.5800e-06 - val_accuracy: 0.7552\n",
      "\n",
      "Epoch 00049: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0049.ckpt\n",
      "Epoch 50/4000\n",
      "275/275 [==============================] - 142s 515ms/step - loss: 2.3776e-04 - accuracy: 0.7297 - val_loss: 5.7729e-06 - val_accuracy: 0.7863\n",
      "\n",
      "Epoch 00050: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0050.ckpt\n",
      "Epoch 51/4000\n",
      "275/275 [==============================] - 142s 516ms/step - loss: 2.2859e-04 - accuracy: 0.7269 - val_loss: 5.0820e-06 - val_accuracy: 0.8114\n",
      "\n",
      "Epoch 00051: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0051.ckpt\n",
      "Epoch 52/4000\n",
      "275/275 [==============================] - 142s 516ms/step - loss: 2.2891e-04 - accuracy: 0.7301 - val_loss: 4.5050e-06 - val_accuracy: 0.8280\n",
      "\n",
      "Epoch 00052: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0052.ckpt\n",
      "Epoch 53/4000\n",
      "275/275 [==============================] - 141s 513ms/step - loss: 2.1901e-04 - accuracy: 0.7247 - val_loss: 5.2541e-06 - val_accuracy: 0.7735\n",
      "\n",
      "Epoch 00053: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0053.ckpt\n",
      "Epoch 54/4000\n",
      "275/275 [==============================] - 140s 510ms/step - loss: 2.3989e-04 - accuracy: 0.7301 - val_loss: 5.8127e-06 - val_accuracy: 0.7916\n",
      "\n",
      "Epoch 00054: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0054.ckpt\n",
      "Epoch 55/4000\n",
      "275/275 [==============================] - 142s 516ms/step - loss: 2.3450e-04 - accuracy: 0.7249 - val_loss: 3.7928e-06 - val_accuracy: 0.7603\n",
      "\n",
      "Epoch 00055: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0055.ckpt\n",
      "Epoch 56/4000\n",
      "275/275 [==============================] - 141s 511ms/step - loss: 2.3431e-04 - accuracy: 0.7232 - val_loss: 3.4202e-06 - val_accuracy: 0.7424\n",
      "\n",
      "Epoch 00056: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0056.ckpt\n",
      "Epoch 57/4000\n",
      "275/275 [==============================] - 143s 520ms/step - loss: 2.1080e-04 - accuracy: 0.7193 - val_loss: 3.7039e-06 - val_accuracy: 0.7425\n",
      "\n",
      "Epoch 00057: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0057.ckpt\n",
      "Epoch 58/4000\n",
      "275/275 [==============================] - 145s 528ms/step - loss: 2.1225e-04 - accuracy: 0.7223 - val_loss: 3.3365e-06 - val_accuracy: 0.7895\n",
      "\n",
      "Epoch 00058: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0058.ckpt\n",
      "Epoch 59/4000\n",
      "275/275 [==============================] - 143s 522ms/step - loss: 2.2056e-04 - accuracy: 0.7214 - val_loss: 3.6918e-06 - val_accuracy: 0.7526\n",
      "\n",
      "Epoch 00059: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0059.ckpt\n",
      "Epoch 60/4000\n",
      "275/275 [==============================] - 142s 515ms/step - loss: 2.1559e-04 - accuracy: 0.7217 - val_loss: 6.4335e-06 - val_accuracy: 0.7741\n",
      "\n",
      "Epoch 00060: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0060.ckpt\n",
      "Epoch 61/4000\n",
      "275/275 [==============================] - 142s 516ms/step - loss: 2.2650e-04 - accuracy: 0.7301 - val_loss: 2.5837e-06 - val_accuracy: 0.7498\n",
      "\n",
      "Epoch 00061: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0061.ckpt\n",
      "Epoch 62/4000\n",
      "275/275 [==============================] - 142s 518ms/step - loss: 2.2680e-04 - accuracy: 0.7235 - val_loss: 2.5580e-06 - val_accuracy: 0.8592\n",
      "\n",
      "Epoch 00062: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0062.ckpt\n",
      "Epoch 63/4000\n",
      "275/275 [==============================] - 145s 526ms/step - loss: 2.3712e-04 - accuracy: 0.7279 - val_loss: 3.3134e-06 - val_accuracy: 0.7431\n",
      "\n",
      "Epoch 00063: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0063.ckpt\n",
      "Epoch 64/4000\n",
      "275/275 [==============================] - 145s 528ms/step - loss: 2.1601e-04 - accuracy: 0.7230 - val_loss: 3.4591e-06 - val_accuracy: 0.8292\n",
      "\n",
      "Epoch 00064: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0064.ckpt\n",
      "Epoch 65/4000\n",
      "275/275 [==============================] - 144s 525ms/step - loss: 2.1792e-04 - accuracy: 0.7194 - val_loss: 4.3381e-06 - val_accuracy: 0.7475\n",
      "\n",
      "Epoch 00065: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0065.ckpt\n",
      "Epoch 66/4000\n",
      "275/275 [==============================] - 145s 526ms/step - loss: 2.1793e-04 - accuracy: 0.7233 - val_loss: 4.5011e-06 - val_accuracy: 0.7455\n",
      "\n",
      "Epoch 00066: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0066.ckpt\n",
      "Epoch 67/4000\n",
      "275/275 [==============================] - 146s 532ms/step - loss: 2.1754e-04 - accuracy: 0.7274 - val_loss: 2.7055e-06 - val_accuracy: 0.7852\n",
      "\n",
      "Epoch 00067: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0067.ckpt\n",
      "Epoch 68/4000\n",
      "275/275 [==============================] - 145s 528ms/step - loss: 1.9650e-04 - accuracy: 0.7352 - val_loss: 1.8384e-06 - val_accuracy: 0.7445\n",
      "\n",
      "Epoch 00068: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0068.ckpt\n",
      "Epoch 69/4000\n",
      "275/275 [==============================] - 146s 530ms/step - loss: 1.9696e-04 - accuracy: 0.7264 - val_loss: 2.2808e-06 - val_accuracy: 0.7441\n",
      "\n",
      "Epoch 00069: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0069.ckpt\n",
      "Epoch 70/4000\n",
      "275/275 [==============================] - 145s 527ms/step - loss: 2.1595e-04 - accuracy: 0.7247 - val_loss: 2.1566e-06 - val_accuracy: 0.7480\n",
      "\n",
      "Epoch 00070: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0070.ckpt\n",
      "Epoch 71/4000\n",
      "275/275 [==============================] - 145s 526ms/step - loss: 2.1311e-04 - accuracy: 0.7251 - val_loss: 4.4181e-06 - val_accuracy: 0.7448\n",
      "\n",
      "Epoch 00071: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0071.ckpt\n",
      "Epoch 72/4000\n",
      "275/275 [==============================] - 145s 527ms/step - loss: 2.2623e-04 - accuracy: 0.7289 - val_loss: 3.7544e-06 - val_accuracy: 0.7470\n",
      "\n",
      "Epoch 00072: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0072.ckpt\n",
      "Epoch 73/4000\n",
      "275/275 [==============================] - 146s 529ms/step - loss: 2.1044e-04 - accuracy: 0.7324 - val_loss: 4.9882e-06 - val_accuracy: 0.7499\n",
      "\n",
      "Epoch 00073: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0073.ckpt\n",
      "Epoch 74/4000\n",
      "275/275 [==============================] - 147s 533ms/step - loss: 2.1492e-04 - accuracy: 0.7299 - val_loss: 2.3296e-06 - val_accuracy: 0.7439\n",
      "\n",
      "Epoch 00074: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0074.ckpt\n",
      "Epoch 75/4000\n",
      "275/275 [==============================] - 146s 532ms/step - loss: 2.0310e-04 - accuracy: 0.7312 - val_loss: 4.4640e-06 - val_accuracy: 0.7457\n",
      "\n",
      "Epoch 00075: saving model to ./chkpnt/0210/seq2seq_multi\\cp-0075.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/gpu:0\"):\n",
    "    model.fit([train_x,train_y],train_y, epochs=4000, callbacks=[callback, cp_callback],validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "01 : 25Epoch\n",
    "02 : 61Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(128,))\n",
    "decoder_state_input_c = Input(shape=(128,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용.\n",
    "# 뒤의 함수 decode_sequence()에 동작을 구현 예정\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태를 버리지 않음.\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(inputs=[decoder_inputs] + decoder_states_inputs, outputs=[decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "      # 입력으로부터 인코더의 상태를 얻음\n",
    "  states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "  # <SOS>에 해당하는 원-핫 벡터 생성\n",
    "  # target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "  # target_seq[0, 0, tar_to_index['\\t']] = 1.\n",
    "  target_seq = input_seq[0]\n",
    "\n",
    "  stop_condition = False\n",
    "  decoded_sentence = \"\"\n",
    "\n",
    "  # stop_condition이 True가 될 때까지 루프 반복\n",
    "  # while not stop_condition:\n",
    "  while _ in range(32):\n",
    "    # 이점 시점의 상태 states_value를 현 시점의 초기 상태로 사용\n",
    "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "    # 예측 결과를 문자로 변환\n",
    "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "    sampled_char = index_to_tar[sampled_token_index]\n",
    "\n",
    "    # 현재 시점의 예측 문자를 예측 문장에 추가\n",
    "    decoded_sentence += sampled_char\n",
    "    \n",
    "    # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
    "    target_seq = np.zeros((1, 1, tar_vocab_size))\n",
    "    target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "    # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
    "    states_value = [h, c]\n",
    "\n",
    "  return decoded_sentence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spleeter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b3c401dacfab8a690b1a7de6c6a9edd3269fc10d243267328a900f27334b3a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
