{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input, TimeDistributed\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=[]\n",
    "train_y=[]\n",
    "\n",
    "for i in range(1,5001):\n",
    "    train.append(pd.read_csv('./masked_dataset/beat/'+str(i)+'.csv.gzip', compression='gzip').to_numpy())\n",
    "    train_y.append(pd.read_csv('./dataset/beat/'+str(i)+'.csv.gzip', compression='gzip').to_numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.array(train)\n",
    "train_y = np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.swapaxes(1,2)\n",
    "train_y = train_y.swapaxes(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# model.add(Input(shape=(9,32)))\n",
    "\n",
    "# inputs = Input(shape=(9,32))\n",
    "# lstm =  tf.keras.layers.Bidirectional(LSTM(units=32, return_sequences=True, activation='sigmoid'))(inputs)\n",
    "# outputs = tf.keras.layers.Bidirectional(LSTM(units=32, return_sequences=False, activation='sigmoid'))(lstm)\n",
    "# forward = LSTM(units=16, return_sequences=True, activation='sigmoid')\n",
    "# backward = LSTM(units=16, return_sequences=True, activation='sigmoid', go_backwards=True)\n",
    "\n",
    "# model.add(tf.keras.layers.Bidirectional(forward, backward_layer=backward, input_shape=(9,32)))\n",
    "# model.add(LSTM(units=32, return_sequences=True, activation='sigmoid', input_shape=(9,32)))\n",
    "model.add(LSTM(units=9, return_sequences=True, activation='sigmoid', input_shape=(32,9)))\n",
    "# model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss = tf.keras.losses.binary_crossentropy, optimizer='rmsprop')\n",
    "model.compile(loss = tf.keras.losses.mse, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train.astype('float32'),train_y.astype('float32'), epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainn=[]\n",
    "testn=[]\n",
    "\n",
    "for i in range(10000,10100):\n",
    "    trainn.append(pd.read_csv('./masked_dataset/beat/'+str(i)+'.csv.gzip', compression='gzip').to_numpy())\n",
    "    testn.append(pd.read_csv('./dataset/beat/'+str(i)+'.csv.gzip', compression='gzip').to_numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainn = np.array(trainn)\n",
    "testn = np.array(testn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 32, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 32, 9)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec = np.zeros_like(train)\n",
    "\n",
    "dec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(dec.shape[0]):\n",
    "    for j in range(dec.shape[1]):\n",
    "        if j != 0:\n",
    "            dec[i][j] = train_y[i][j-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainn = trainn.swapaxes(1,2)\n",
    "testn = testn.swapaxes(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "decn = np.zeros_like(testn)\n",
    "for i in range(decn.shape[0]):\n",
    "    for j in range(decn.shape[1]):\n",
    "        if j != 0:\n",
    "            decn[i][j] = testn[i][j-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 1, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 1, 0, ..., 1, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[1, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 1, 0, 0],\n",
       "        ...,\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 1, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 1, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 1, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 1, 0, ..., 0, 0, 1],\n",
       "        [0, 0, 0, ..., 0, 0, 1],\n",
       "        [0, 1, 0, ..., 1, 0, 1],\n",
       "        ...,\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 1, 0, 1],\n",
       "        [1, 1, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[1, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 1, 0, 0],\n",
       "        ...,\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 1, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 1, 0, 0],\n",
       "        ...,\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 1, 0, 0],\n",
       "        [1, 1, 0, ..., 0, 0, 0]]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 1, 0, 0],\n",
       "        ...,\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 1, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 1, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 1, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 1],\n",
       "        [0, 0, 0, ..., 0, 0, 1],\n",
       "        ...,\n",
       "        [1, 0, 0, ..., 0, 0, 1],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 1, 0, 1]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 1, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 1, 0, 0]]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdf = model.predict(trainn)\n",
    "\n",
    "asdf = asdf.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(trainn, testn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 10\n",
    "print(trainn[i])\n",
    "print('-'*10)\n",
    "print(asdf[i].astype(int))\n",
    "print('-'*10)\n",
    "print(testn[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(32,9))\n",
    "encoder_lstm = LSTM(units=512, return_state=True, dropout=0.1, unroll=True, recurrent_dropout=0.1)\n",
    "\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "decoder_inputs = Input(shape=(None,9))\n",
    "decoder_lstm = LSTM(units=512, return_sequences=True, return_state=True, dropout=0.1, recurrent_dropout=0.1)\n",
    "\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state = encoder_states)\n",
    "\n",
    "decoder_dense = Dense(9, activation='sigmoid')\n",
    "\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if model is not None:\n",
    "del model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.binary_crossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "125/125 [==============================] - 28s 194ms/step - loss: 0.3213 - val_loss: 0.2909\n",
      "Epoch 2/5000\n",
      "125/125 [==============================] - 23s 186ms/step - loss: 0.2698 - val_loss: 0.2636\n",
      "Epoch 3/5000\n",
      "125/125 [==============================] - 24s 189ms/step - loss: 0.2464 - val_loss: 0.2508\n",
      "Epoch 4/5000\n",
      "125/125 [==============================] - 24s 189ms/step - loss: 0.2350 - val_loss: 0.2431\n",
      "Epoch 5/5000\n",
      "125/125 [==============================] - 23s 183ms/step - loss: 0.2266 - val_loss: 0.2369\n",
      "Epoch 6/5000\n",
      "125/125 [==============================] - 23s 183ms/step - loss: 0.2186 - val_loss: 0.2252\n",
      "Epoch 7/5000\n",
      "125/125 [==============================] - 23s 186ms/step - loss: 0.2107 - val_loss: 0.2229\n",
      "Epoch 8/5000\n",
      "125/125 [==============================] - 23s 187ms/step - loss: 0.2018 - val_loss: 0.2123\n",
      "Epoch 9/5000\n",
      "125/125 [==============================] - 23s 187ms/step - loss: 0.1939 - val_loss: 0.2086\n",
      "Epoch 10/5000\n",
      "125/125 [==============================] - 23s 186ms/step - loss: 0.1880 - val_loss: 0.2080\n",
      "Epoch 11/5000\n",
      "125/125 [==============================] - 23s 184ms/step - loss: 0.1817 - val_loss: 0.2047\n",
      "Epoch 12/5000\n",
      "125/125 [==============================] - 23s 188ms/step - loss: 0.1765 - val_loss: 0.2036\n",
      "Epoch 13/5000\n",
      "125/125 [==============================] - 23s 188ms/step - loss: 0.1700 - val_loss: 0.2011\n",
      "Epoch 14/5000\n",
      "125/125 [==============================] - 24s 189ms/step - loss: 0.1655 - val_loss: 0.1960\n",
      "Epoch 15/5000\n",
      "125/125 [==============================] - 23s 185ms/step - loss: 0.1595 - val_loss: 0.1959\n",
      "Epoch 16/5000\n",
      "125/125 [==============================] - 23s 182ms/step - loss: 0.1533 - val_loss: 0.1957\n",
      "Epoch 17/5000\n",
      "125/125 [==============================] - 23s 184ms/step - loss: 0.1486 - val_loss: 0.1945\n",
      "Epoch 18/5000\n",
      "125/125 [==============================] - 23s 185ms/step - loss: 0.1424 - val_loss: 0.1969\n",
      "Epoch 19/5000\n",
      "125/125 [==============================] - 23s 186ms/step - loss: 0.1378 - val_loss: 0.1918\n",
      "Epoch 20/5000\n",
      "125/125 [==============================] - 23s 181ms/step - loss: 0.1327 - val_loss: 0.1921\n",
      "Epoch 21/5000\n",
      "125/125 [==============================] - 23s 184ms/step - loss: 0.1278 - val_loss: 0.1905\n",
      "Epoch 22/5000\n",
      "125/125 [==============================] - 24s 193ms/step - loss: 0.1231 - val_loss: 0.1898\n",
      "Epoch 23/5000\n",
      "125/125 [==============================] - 23s 186ms/step - loss: 0.1188 - val_loss: 0.1892\n",
      "Epoch 24/5000\n",
      "125/125 [==============================] - 23s 185ms/step - loss: 0.1149 - val_loss: 0.1950\n",
      "Epoch 25/5000\n",
      "125/125 [==============================] - 23s 184ms/step - loss: 0.1110 - val_loss: 0.1885\n",
      "Epoch 26/5000\n",
      "125/125 [==============================] - 23s 185ms/step - loss: 0.1065 - val_loss: 0.1909\n",
      "Epoch 27/5000\n",
      "125/125 [==============================] - 23s 185ms/step - loss: 0.1036 - val_loss: 0.1897\n",
      "Epoch 28/5000\n",
      "125/125 [==============================] - 23s 186ms/step - loss: 0.1001 - val_loss: 0.1916\n",
      "Epoch 29/5000\n",
      "125/125 [==============================] - 23s 187ms/step - loss: 0.0978 - val_loss: 0.1960\n",
      "Epoch 30/5000\n",
      "125/125 [==============================] - 23s 182ms/step - loss: 0.0947 - val_loss: 0.1967\n",
      "Epoch 31/5000\n",
      "125/125 [==============================] - 23s 185ms/step - loss: 0.0911 - val_loss: 0.1963\n",
      "Epoch 32/5000\n",
      "125/125 [==============================] - 23s 186ms/step - loss: 0.0880 - val_loss: 0.1952\n",
      "Epoch 33/5000\n",
      "125/125 [==============================] - 24s 188ms/step - loss: 0.0855 - val_loss: 0.1968\n",
      "Epoch 34/5000\n",
      "125/125 [==============================] - 23s 186ms/step - loss: 0.0842 - val_loss: 0.1989\n",
      "Epoch 35/5000\n",
      "125/125 [==============================] - 23s 182ms/step - loss: 0.0812 - val_loss: 0.2026\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/gpu:0'):\n",
    "    model.fit(x=[train, dec], y=train_y, epochs=5000, callbacks=callback, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 64ms/step - loss: 0.2425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.24249206483364105"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=[trainn, decn], y=testn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd = model.predict(x=[trainn, decn])\n",
    "asd = asd.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 1 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 1 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 1 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [1 0 0 1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 1 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 1 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 1 0 1 0 0]\n",
      " [0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 1 0 0]]\n",
      "----------\n",
      "[[0 1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 1 0 1 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 1 0 1 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 1 0 1 0 0]\n",
      " [0 1 0 0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 1 0 1 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 1 1 0 1 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 1 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 1 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 1 0 1 0 0]]\n",
      "----------\n",
      "[[0 1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 1 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 1 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 1 0 1 0 0]\n",
      " [0 0 0 0 1 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 1 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [1 0 0 1 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 1 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 1 0 0]\n",
      " [0 1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 1 0 1 0 0]\n",
      " [0 0 0 0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "i = 10\n",
    "print(trainn[i])\n",
    "print('-'*10)\n",
    "print(asd[i].astype(int))\n",
    "print('-'*10)\n",
    "print(testn[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('spleeter')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b3c401dacfab8a690b1a7de6c6a9edd3269fc10d243267328a900f27334b3a4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
